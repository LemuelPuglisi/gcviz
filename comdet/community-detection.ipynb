{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the graph as an undirected and unweighted graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as cm\n",
    "from modules import cytoscape as cs \n",
    "\n",
    "G = nx.read_weighted_edgelist('../dataset/gene_edges.tsv', delimiter=\"\\t\")\n",
    "\n",
    "# the \"weight\" on the graph indicates the\n",
    "# activation (+1) and deactivation (-1) of  \n",
    "# genes. We can set all to 1 for community\n",
    "# detection pourpose \n",
    "\n",
    "for u,v,d in G.edges(data=True):\n",
    "    d['weight']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_partition(json_partition, name, directory = '../partitions'):\n",
    "    with open(f'{directory}/{name}.json', 'w') as f:\n",
    "        f.write(json_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clauset-Newman-Moore Modularity maximization\n",
    "\n",
    "* [Link to the paper](https://arxiv.org/abs/cond-mat/0408187)\n",
    "* [Link to implementation](https://github.com/networkx/networkx/blob/main/networkx/algorithms/community/modularity_max.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm_partition = cm.greedy_modularity_communities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnm produced 92 clusters with 0.616 modularity.\n"
     ]
    }
   ],
   "source": [
    "cnm_nclusters = len(cnm_partition)\n",
    "cnm_modularity = cm.modularity(G, cnm_partition)\n",
    "\n",
    "print(f\"cnm produced {cnm_nclusters} clusters with {cnm_modularity:.3f} modularity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm_json = cs.partition_to_cytospace_json(G, cnm_partition)\n",
    "save_partition(cnm_json, 'cnm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Girvan-Newman edge-betweenness centrality based \n",
    "* [Link to the paper](https://www.pnas.org/content/99/12/7821)\n",
    "* [Link to implementation](https://github.com/networkx/networkx/blob/main/networkx/algorithms/community/centrality.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04169909755870315\n"
     ]
    }
   ],
   "source": [
    "## Implementare un algoritmo di selezione per la partizione con modularità migliore\n",
    "\n",
    "\n",
    "# T = nx.karate_club_graph()\n",
    "\n",
    "gn_communities = cm.girvan_newman(G)\n",
    "\n",
    "# parameters \n",
    "goes_down = 0\n",
    "goes_down_limit = 5 \n",
    "iterations = 20\n",
    "\n",
    "# variables \n",
    "partitions_list = []\n",
    "modularity_list = []\n",
    "\n",
    "for i in range(iterations): \n",
    "    current_partition = next(gn_communities)\n",
    "    partitions_list.append(current_partition)\n",
    "    modularity_list.append(cm.modularity(G, current_partition))\n",
    "    \n",
    "    if (i > 0 and modularity_list[i-1] > modularity_list[i]):\n",
    "        goes_down += 1\n",
    "        if (goes_down > goes_down_limit):\n",
    "            print(f\"stop iteration {i} due to modularity decrease\")\n",
    "            break\n",
    "    \n",
    "best_modularity = max(modularity_list)\n",
    "best_iteration  = modularity_list.index(best_modularity)\n",
    "best_partition  = partitions_list[best_iteration]\n",
    "\n",
    "print(best_modularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm_json = cs.partition_to_cytospace_json(G, best_partition)\n",
    "save_partition(cnm_json, 'gn') # 0.042 mod "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FluidC - Asynchronous Fluid Communities algorithm\n",
    "\n",
    "* [Link to paper](https://arxiv.org/pdf/1703.09307.pdf)\n",
    "* [Link to implementation](https://github.com/networkx/networkx/blob/main/networkx/algorithms/community/asyn_fluid.py)\n",
    "\n",
    "Since FluidC works only on connected graphs, we can compute the connected components of $G$ and apply the algorithm on those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ccgen = nx.algorithms.components.connected_components(G) \n",
    "\n",
    "# connected components \n",
    "cc = [ c for c in sorted( ccgen, key=len, reverse=True ) ]\n",
    "\n",
    "# calculate the number of clusters to take out from the \n",
    "# connected components using the logarithm of its dimension\n",
    "ncomm = lambda c: int(np.floor(np.log(len(c))))\n",
    "\n",
    "# initialize an empty set that will be filled with out\n",
    "# graph partition\n",
    "partition = []\n",
    "\n",
    "for ccomponent in cc:\n",
    "    \n",
    "    number_of_communities = ncomm(ccomponent)\n",
    "    \n",
    "    if (number_of_communities > 1):\n",
    "        \n",
    "        # extract the connected component from the graph G\n",
    "        C = G.subgraph(ccomponent)\n",
    "        \n",
    "        # execute the algorithm on the connected subgraph \n",
    "        fluidc_community_generator = cm.asyn_fluidc(C, number_of_communities)\n",
    "        \n",
    "        # extract the communities\n",
    "        communities = [ cluster for cluster in fluidc_community_generator ]\n",
    "        \n",
    "        # put the communities inside the partition\n",
    "        partition += communities\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # insert the component as a community inside the partition\n",
    "        partition.append(ccomponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6339086029546955"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.modularity(G, partition)\n",
    "# 0.6339086029546955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluidc_json = cs.partition_to_cytospace_json(G, partition)\n",
    "save_partition(fluidc_json, 'fluidc') # 0.042 mod "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernighan-Lin bisection\n",
    "\n",
    "* [Link to paper](https://ieeexplore.ieee.org/document/6771089)\n",
    "* [Link to implementation](https://github.com/networkx/networkx/blob/main/networkx/algorithms/community/kernighan_lin.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = [node for node in G.nodes]\n",
    "\n",
    "# store the partition of the graph G at\n",
    "# each level of bisection\n",
    "dendogram = [[all_nodes]]\n",
    "\n",
    "# flag to stop the iteration\n",
    "every_cluster_is_node = False \n",
    "\n",
    "# iteration counters \n",
    "prev_iter = 0\n",
    "curr_iter = 1\n",
    "max_iter  = 20\n",
    "\n",
    "while (not every_cluster_is_node and curr_iter < max_iter):\n",
    "    \n",
    "    curr_partition = []\n",
    "    prev_partition = dendogram[prev_iter]\n",
    "    \n",
    "    # suppose every flag is a single node\n",
    "    every_cluster_is_node = True\n",
    "    \n",
    "    # for each community in the previous partitioning, \n",
    "    # apply the bisection if the number of nodes is > 1\n",
    "    # add the bisection in the current partition \n",
    "    for pc in prev_partition:\n",
    "        subG = G.subgraph(pc)\n",
    "        if (subG.number_of_nodes() < 2):\n",
    "            curr_partition.append(pc)\n",
    "            # if every cluster is a node, in the\n",
    "            # end this will produce True\n",
    "            every_cluster_is_node &= True\n",
    "        else:\n",
    "            pc_communities = cm.kernighan_lin_bisection(subG)\n",
    "            curr_partition += pc_communities\n",
    "            # if there is at least on cluster that\n",
    "            # is composed of many nodes, then this \n",
    "            # flag will be set to False. \n",
    "            every_cluster_is_node &= False\n",
    "    \n",
    "    dendogram.append(curr_partition)\n",
    "    prev_iter += 1  \n",
    "    curr_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.061722277284057145\n"
     ]
    }
   ],
   "source": [
    "# remove the first partition (full graph)\n",
    "valid_partitions = dendogram[1:-1]\n",
    "\n",
    "# calculate the modularities \n",
    "kl_modularities = [ cm.modularity(G, p) for p in dendogram[1:-1] ]\n",
    "\n",
    "# take the best partition \n",
    "best_modl = max(kl_modularities)\n",
    "best_iter = kl_modularities.index(best_modl)\n",
    "best_part = valid_partitions[best_iter]\n",
    "\n",
    "print(best_modl)\n",
    "#0.061722277284057145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_json = cs.partition_to_cytospace_json(G, best_part)\n",
    "save_partition(kl_json, 'kl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Vec graph embedding\n",
    "\n",
    "* [Link to paper](https://snap.stanford.edu/node2vec/)\n",
    "* [Link to implementation](https://github.com/eliorc/node2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7a5f612ba640d59ea342a40562d7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Computing transition probabilities'), FloatProgress(value=0.0, max=3498.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "\n",
    "n2v = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = n2v.fit(window=10, min_count=1, batch_words=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('n2v/embeddings.emb')\n",
    "model.save('n2v/embeddings.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use kmeans from nodes embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6537718239372098"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# dict: node ID to embedding index \n",
    "vocab = model.wv.key_to_index\n",
    "\n",
    "# nodes embeddings \n",
    "vectors = model.wv.vectors \n",
    "\n",
    "# Graph nodes IDs \n",
    "V = [node for node in G.nodes]\n",
    "\n",
    "# use kmeans (k=60) on vectors\n",
    "kmeans = KMeans(n_clusters=60, random_state=0)\n",
    "kmeans.fit(vectors)\n",
    "\n",
    "# get the labels (for each node, returns the cluster)\n",
    "node_labels = kmeans.labels_\n",
    "\n",
    "# create a partition of G \n",
    "n2v_partition = [ [] for _ in range(60) ]\n",
    "for node in V:\n",
    "    node_index = vocab.get(node)\n",
    "    node_cluster = node_labels[node_index]\n",
    "    n2v_partition[node_cluster].append(node)\n",
    "    \n",
    "# print the modularity\n",
    "cm.modularity(G, n2v_partition)\n",
    "# 0.6537718239372098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_json = cs.partition_to_cytospace_json(G, n2v_partition)\n",
    "save_partition(n2v_json, 'n2v') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral clustering \n",
    "* [Reference (1)](http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.160.2324)\n",
    "* [Reference (2)](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.165.9323)\n",
    "* [Reference (3)](https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2003kwayICCV.pdf)\n",
    "* [Link to implementation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def spectral_clustering(G, k, n_init=100):\n",
    "    A = nx.to_numpy_matrix(G)\n",
    "    sc = SpectralClustering(\n",
    "        k, affinity='precomputed', \n",
    "        n_init=n_init,\n",
    "        assign_labels='discretize').fit(A)\n",
    "    # extract nodes and corresponding labels \n",
    "    V, labels = G.nodes(), sc.labels_\n",
    "    # create the partition and return it \n",
    "    partition = [ [] for _ in range(k) ]\n",
    "    for index, nodeid in enumerate(V):\n",
    "        label = labels[index]\n",
    "        partition[label].append(nodeid)\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6535616519292664"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "partition = spectral_clustering(G, 60, 500)\n",
    "cm.modularity(G, partition)\n",
    "# 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_json = cs.partition_to_cytospace_json(G, partition)\n",
    "save_partition(sc_json, 'sc') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louvain - Greedy modularity optimization\n",
    "\n",
    "* [Link to paper](https://arxiv.org/abs/0803.0476)\n",
    "* [Link to implementation](https://github.com/taynaud/python-louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as louvain\n",
    "\n",
    "node_to_label = louvain.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6887668389489657"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cluster = max(node_to_label.values()) + 1\n",
    "partition = [ [] for i in range(n_cluster) ]\n",
    "\n",
    "for node, label in partition_as_ids.items():\n",
    "    partition[label].append(node)\n",
    "    \n",
    "cm.modularity(G, partition)\n",
    "#0.6887668389489657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvn_json = cs.partition_to_cytospace_json(G, partition)\n",
    "save_partition(lvn_json, 'lvn') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
